{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hospital_Stays_SMPC_DP_upload.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-KKKediaUCt",
        "outputId": "90087cc4-c8fb-45d0-e629-8cb842aa0518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount the data on your google drive\n",
        "#mounting this will help you to call the files from the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-HdT1_qbIdT"
      },
      "source": [
        "#install all the syft library required\n",
        "#After installed all the library, you have to restart the code again\n",
        "!pip install 'syft[udacity]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afzsu-isciaY"
      },
      "source": [
        "# IMPORT MODULES\n",
        "# TURN ON the GPU !\n",
        "#import all the required libraries\n",
        "\n",
        "import os\n",
        "from operator import itemgetter    \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "get_ipython().magic(u'matplotlib inline')\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import preprocessing\n",
        "#from sklearn.preprocessing import Imputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
        "#from sklearn.cross_validation import KFold, cross_val_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, preprocessing\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
        "#from sklearn.utils.fixes import signature\n",
        "#from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.preprocessing import shuffle_arrays_unison\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "#from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.utils import np_utils\n",
        "#from keras.utils import to_categorical\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMkxIlpMV-oF",
        "outputId": "10ef9994-0b96-42fb-b2d3-edcee6852918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tmimic3d.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8C5VrXlc5_Y",
        "outputId": "49e64299-3a3e-40c1-d618-89a9cca87bbc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#upload the dataset from your device\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41861ecd-f3b2-4f23-9b82-fd6106d0e089\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41861ecd-f3b2-4f23-9b82-fd6106d0e089\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mimic3d.csv to mimic3d.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBYvwf0ee5hd",
        "outputId": "842c2165-4a6a-47e7-e15a-96d88c209a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#call the dataset and data preprocessing\n",
        "data = pd.read_csv('mimic3d.csv')\n",
        "print(\"With id\", data.shape)\n",
        "data_full = data.drop('hadm_id', 1)\n",
        "print(\"No id\",data_full.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With id (58976, 28)\n",
            "No id (58976, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4qxeEWTe-9d",
        "outputId": "4dd0caba-e903-42c4-cfec-2bca25f1462e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Label = LOS\n",
        "#data preprocessing\n",
        "\n",
        "y = data_full['LOSgroupNum']\n",
        "X = data_full.drop('LOSgroupNum', 1)\n",
        "X = X.drop('LOSdays', 1)\n",
        "X = X.drop('ExpiredHospital', 1)\n",
        "X = X.drop('AdmitDiagnosis', 1)\n",
        "X = X.drop('AdmitProcedure', 1)\n",
        "X = X.drop('marital_status', 1)\n",
        "X = X.drop('ethnicity', 1)\n",
        "X = X.drop('religion', 1)\n",
        "X = X.drop('insurance', 1)\n",
        "\n",
        "print(\"y - Labels\", y.shape)\n",
        "print(\"X - No Label No id \", X.shape)\n",
        "print(X.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y - Labels (58976,)\n",
            "X - No Label No id  (58976, 18)\n",
            "Index(['gender', 'age', 'admit_type', 'admit_location', 'NumCallouts',\n",
            "       'NumDiagnosis', 'NumProcs', 'NumCPTevents', 'NumInput', 'NumLabs',\n",
            "       'NumMicroLabs', 'NumNotes', 'NumOutput', 'NumRx', 'NumProcEvents',\n",
            "       'NumTransfers', 'NumChartEvents', 'TotalNumInteract'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFBemIEwfEmz",
        "outputId": "456751a7-dee0-4a5c-ff26-561de6f8b28a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X.shape)\n",
        "categorical_columns = [\n",
        "                    'gender',                     \n",
        "                    'admit_type',\n",
        "                    'admit_location'\n",
        "                      ]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    #if the original column is present replace it with a one-hot\n",
        "    if col in X.columns:\n",
        "        one_hot_encoded = pd.get_dummies(X[col])\n",
        "        X = X.drop(col, axis=1)\n",
        "        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n",
        "        \n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(58976, 18)\n",
            "(58976, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGOaDn3efPzP",
        "outputId": "a1788563-24ba-4e39-b349-3323c14ef723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data_full.shape)\n",
        "print(X.shape)\n",
        "#XnotNorm = np.array(X.copy())\n",
        "XnotNorm = X.copy()\n",
        "print('XnotNorm ', XnotNorm.shape)\n",
        "\n",
        "ynotNorm = y.copy()\n",
        "print('ynotNorm ', ynotNorm.shape)   #data normalization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(58976, 27)\n",
            "(58976, 30)\n",
            "XnotNorm  (58976, 30)\n",
            "ynotNorm  (58976,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf3WXstkfUZz",
        "outputId": "5c5dda8e-9a07-4e09-dd67-3cfec04096a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Normalize X\n",
        "\n",
        "x = XnotNorm.values #returns a numpy array\n",
        "scaler = preprocessing.StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "XNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n",
        "print(XNorm)\n",
        "#print(y)\n",
        "print('X normalized')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            age  ...  TRSF WITHIN THIS FACILITY\n",
            "0     -0.691792  ...                  -0.009208\n",
            "1      0.230296  ...                  -0.009208\n",
            "2     -0.192328  ...                  -0.009208\n",
            "3      0.768180  ...                  -0.009208\n",
            "4      0.268716  ...                  -0.009208\n",
            "...         ...  ...                        ...\n",
            "58971  0.268716  ...                  -0.009208\n",
            "58972  0.191876  ...                  -0.009208\n",
            "58973 -1.152835  ...                  -0.009208\n",
            "58974  0.614499  ...                  -0.009208\n",
            "58975  1.344485  ...                  -0.009208\n",
            "\n",
            "[58976 rows x 30 columns]\n",
            "X normalized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npd3YyDpfYYG",
        "outputId": "757e38a8-f769-4209-bd41-e39c9464fcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# SPLIT data into Train & Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.01, random_state=7)\n",
        "#X_train=XNorm[0:58386]\n",
        "#y_train=y[0:58386]\n",
        "#X_test=XNorm[58386:58386+590]\n",
        "#y_test=y[58386:58386+590]\n",
        "print ('X_train: ', X_train.shape)\n",
        "print ('X_test: ', X_test.shape)\n",
        "print ('y_train: ', y_train.shape)\n",
        "print ('y_test: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (58386, 30)\n",
            "X_test:  (590, 30)\n",
            "y_train:  (58386,)\n",
            "y_test:  (590,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW9cM7tDpOCx"
      },
      "source": [
        "#categorical of y_data\n",
        "y_test=y_test.values.tolist()\n",
        "y_train=y_train.values.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk23ALxjbulD"
      },
      "source": [
        "X_train=pd.DataFrame(X_train).to_numpy()\n",
        "#y_train=pd.DataFrame(y_train).to_numpy()\n",
        "X_test=pd.DataFrame(X_test).to_numpy()\n",
        "#y_test=pd.DataFrame(y_test).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIeP9VUWfcFg",
        "outputId": "042cec31-8be5-4c2f-d246-04bffb244bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#devide the data into m model owners\n",
        "import numpy as np\n",
        "\n",
        "j=0\n",
        "M=10  #number of model owners=10\n",
        "number=len(X_train)\n",
        "k=number/M\n",
        "#print(x_train)\n",
        "\n",
        "for x in range(0,M):\n",
        "             globals()['x_train_split%s' % x]=X_train[int(j):int(k+j)]\n",
        "             globals()['y_train_split%s' % x]=y_train[int(j):int(k+j)]\n",
        "             j=k\n",
        "print(x_train_split0.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5838, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04F2dpEteFlA"
      },
      "source": [
        "#take 500 test data from all test datasets\n",
        "x_test=X_test[0:500]\n",
        "y_test=y_test[0:500]\n",
        "#y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqTrKydShOh1"
      },
      "source": [
        "#import all the torch libraries as we are going to use pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lstUiQAZhWmr"
      },
      "source": [
        "#initialize required parameters\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yksjNqqWhaP_",
        "outputId": "39e85d9c-70af-4425-c73d-d18f0b3057b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import the syft libraries\n",
        "#create two virtual workers and one crypto_provider\n",
        "import syft as sy\n",
        "hook = sy.TorchHook(torch) \n",
        "client = sy.VirtualWorker(hook, id=\"client\")\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.4.so'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMH4Hh_JhfbZ"
      },
      "source": [
        "epochs = 80  #number of epoches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIKmXhmyhiCO"
      },
      "source": [
        "#argument function\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 50\n",
        "        self.epochs = epochs\n",
        "        self.lr = 0.001\n",
        "        self.log_interval = 100\n",
        "\n",
        "args = Arguments()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrgoAZXhlq0"
      },
      "source": [
        "#transform all numpy train vectors into torch tensor\n",
        "for i in range(0,M):\n",
        "     globals()['tensor_x%s' % i] =torch.Tensor(globals()['x_train_split%s' % i]) # transform to torch tensor\n",
        "     globals()['tensor_y%s' % i] = torch.Tensor(globals()['y_train_split%s' % i])\n",
        "     globals()['tensor_y%s' % i]=globals()['tensor_y%s' % i].type(torch.LongTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a6SeyGwiqA1"
      },
      "source": [
        "#transform test vectors into torch tensor\n",
        "test_x=torch.Tensor(x_test)\n",
        "test_y=torch.Tensor(y_test)\n",
        "#tensor_x=tensor_x.type(torch.LongTensor)\n",
        "#test_x=test_x.type(torch.LongTensor)\n",
        "test_y=test_y.type(torch.LongTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyI_ULQQi-2k"
      },
      "source": [
        "for iter in range(0,M):\n",
        "  globals()['my_dataset%s' % iter] = TensorDataset(globals()['tensor_x%s' % iter],globals()['tensor_y%s' % iter]) \n",
        "  globals()['train_loader%s' % iter] = DataLoader(globals()['my_dataset%s' % iter],batch_size=args.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohZR4cvZjDjv"
      },
      "source": [
        "#create test dataset\n",
        "test_datasets=TensorDataset(test_x,test_y) \n",
        "test_case_loader=DataLoader(test_datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkenM1bUjGco"
      },
      "source": [
        "test_loader = DataLoader(test_datasets,batch_size=args.test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr-kxJkpjL4i"
      },
      "source": [
        "#create private test loader where client secretly shared their data to worker1 and worker2\n",
        "private_test_loader = []\n",
        "for data, target in test_loader:\n",
        "    private_test_loader.append((\n",
        "        data.fix_precision().share(alice, bob, crypto_provider=crypto_provider),\n",
        "        target.fix_precision().share(alice, bob, crypto_provider=crypto_provider)\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg2Swf6_jNaD"
      },
      "source": [
        "#create private test loader where client secretly shared their data to worker1 and worker2\n",
        "private_new_loader = []\n",
        "for data, target in test_case_loader:\n",
        "    private_new_loader.append((\n",
        "        data.fix_precision().share(alice, bob, crypto_provider=crypto_provider),\n",
        "        target.fix_precision().share(alice, bob, crypto_provider=crypto_provider)\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aC9nuMbjRkB"
      },
      "source": [
        "#Feed forward Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(30, 500)\n",
        "        self.fc2 = nn.Linear(500, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 30)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhuBSuQ4jVLT"
      },
      "source": [
        "#training is local training so no encryption \n",
        "def train(args, model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7yW3c4yjZJt"
      },
      "source": [
        "#train data\n",
        "for iter in range (0,M):\n",
        "\n",
        "  globals()['model%s' % iter]=Net()\n",
        "  optimizer = torch.optim.Adam(globals()['model%s' % iter].parameters(), lr=args.lr)\n",
        "  train_loader=0\n",
        "  train_loader=globals()['train_loader%s' % iter]\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "     train(args, globals()['model%s' % iter], train_loader, optimizer, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmfTPPawk5ap"
      },
      "source": [
        "#test data\n",
        "def test(args, model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            output = F.log_softmax(output, dim=1)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHA6GYi1tocT"
      },
      "source": [
        "for iter in range (0,M):\n",
        "     test(args, globals()['model%s' % iter], test_case_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebd6FhB2tt8B"
      },
      "source": [
        "#secure evaluation \n",
        "import timeit\n",
        "start1 = timeit.default_timer()\n",
        "for iter in range (0,M):\n",
        "  globals()['model%s' % iter].fix_precision().share(alice, bob, crypto_provider=crypto_provider)\n",
        "stop1 = timeit.default_timer()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRN2EIe99YvE",
        "outputId": "f4f34aa4-7bcf-47a3-d0ec-8aec24859417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stop1-start1  #required time to model owner's secret share their model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06849979500111658"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG31OtRjtzyn"
      },
      "source": [
        "def produce_probability(args, model, test_loader):\n",
        "    model.eval()\n",
        "    n_correct_priv = 0\n",
        "    n_correct_sum = 0\n",
        "    n_total = 0\n",
        "    actuals = []\n",
        "    predictions = []\n",
        "    yhat=[]\n",
        "    k=0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader[0:500]:\n",
        "            output = model(data)\n",
        "            #print(output.shape)\n",
        "            pred = output.argmax(dim=1)\n",
        "            #print(pred.shape) \n",
        "            #n_correct_priv = pred.eq(target.view_as(pred))#.sum()\n",
        "            #out=n_correct_priv.copy().get().float_precision().long().item()\n",
        "            #print(out)\n",
        "            #n_total += args.test_batch_size\n",
        "            #pred = output.argmax(dim=1) \n",
        "            #n_correct_priv += pred.eq(target.view_as(pred)).sum()\n",
        "            #n_total += args.test_batch_size\n",
        "\n",
        "            #n_correct = n_correct_priv.copy().get().float_precision().long().item()\n",
        "            \n",
        "            \n",
        "            outputs=torch.sum(output, dim=0)\n",
        "            \n",
        "\n",
        "            #yhat=[]\n",
        "            for i in range(4):\n",
        "              z=0\n",
        "              #z=outputs[i].copy().get().float_precision().long().item()\n",
        "              z=outputs[i].copy().get().float_precision().long().item()\n",
        "              \n",
        "              \n",
        "              \n",
        "              yhat.append(z)\n",
        "\n",
        "            #yhat=np.clip(yhat, 0, 1)\n",
        "            #k=np.argmax(yhat)\n",
        "            #actuals.append(k)\n",
        "            \n",
        "\n",
        "            \n",
        "    \n",
        "            \n",
        "            \n",
        "            #print(k)\n",
        "            k=k+1\n",
        "    \n",
        "        return yhat\n",
        "\n",
        "\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5n-CetdIc0R"
      },
      "source": [
        "from joblib import Parallel, delayed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F6msDy0t3I3"
      },
      "source": [
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "def training(iter):\n",
        "#for iter in range(0,10):\n",
        "    y_actual=produce_probability(args,globals()['model%s' % iter],private_new_loader)\n",
        "    y_array=np.array(y_actual)\n",
        "    y_probability=y_array.reshape(500,4)\n",
        "    import pandas as pd \n",
        "  #'y'+str(iter)=y_probability\n",
        "    pd.DataFrame(y_probability).to_csv('/content/gdrive/.....'+'y'+str(iter)+'.csv') #save inference files in your directory\n",
        "   #iter=iter+1\n",
        "  \n",
        "\n",
        "#stop = timeit.default_timer()\n",
        "\n",
        "Parallel(n_jobs=2, require='sharedmem')(\n",
        " delayed(training)(i) for i in range(0,10))\n",
        "stop = timeit.default_timer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ueib9I-lDTH",
        "outputId": "2876e531-1c57-427f-9a85-79875e126c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Time: ', stop - start) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  1552.9209599880014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOJZ-LOUuQ4N"
      },
      "source": [
        "#compute label\n",
        "def label(my_list):\n",
        "  import numpy as np\n",
        "  my_array=np.array(my_list)\n",
        "  p=np.zeros(my_array.shape)\n",
        "  b=my_array.max(-1)\n",
        "  condition = my_array == b[..., np.newaxis]\n",
        "  c = np.where(condition, 1, 0)\n",
        "  final=np.multiply(c, my_array)\n",
        "  #my_sum=np.sum(final,axis=0)\n",
        "  labels=np.argmax(final, axis=1)\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD8qqEnAutM2"
      },
      "source": [
        "#function for vote counting\n",
        "def vote(my_list):\n",
        "  import numpy as np\n",
        "  my_array=np.array(my_list)\n",
        "  p=np.zeros(my_array.shape)\n",
        "  b=my_array.max(-1)\n",
        "  condition = my_array == b[..., np.newaxis]\n",
        "  c = np.where(condition, 1, 0)\n",
        "  final=np.multiply(c, my_array)\n",
        "  #my_sum=np.sum(final,axis=0)\n",
        "  labels=np.argmax(final, axis=1)\n",
        "  return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3066Rp-ubot"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=y_test[0:500]    #total prediction vector/actual prediction\n",
        "#y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbpRf-WSqKvo"
      },
      "source": [
        "#df=pd.read_csv('y0.csv')\n",
        "#define vector of zeros\n",
        "df=np.zeros(500*4)\n",
        "df=df.reshape(500,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QLaHVrQq0HZ",
        "outputId": "33cd64be-49b9-4078-9bda-868b5e371f2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#call the saved prediction output from the drive\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "from google.colab import drive \n",
        "import pandas as pd\n",
        "sum=np.zeros(500*4)\n",
        "sum=sum.reshape(500,4)\n",
        "for iter in range (0,10):\n",
        "  y=np.zeros(df.shape)\n",
        "  y=pd.read_csv('......../Hospitals10/'+'y'+str(iter)+'.csv')   #save your drive name where the inference vector are saved\n",
        "  #y=y_probability\n",
        "  y=y.drop(columns='Unnamed: 0')\n",
        "  yd=pd.DataFrame(y).to_numpy()\n",
        "  #yd=yd*10\n",
        "  yd=vote(yd)\n",
        "  sum=yd+sum\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print(stop-start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.040931784999997944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afQ3MG6prYKb"
      },
      "source": [
        "#create the labels\n",
        "lab=label(sum)\n",
        "sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVHXZAsOreGk",
        "outputId": "fd79ed29-54f3-4cf4-82ff-1a067703c031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#clear accuracy\n",
        "accuracy_score(y_pred,lab)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.60000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVd7kC_iyGSO"
      },
      "source": [
        "#Client_acc_40_C=np.zeros(len(noise))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlxylUO8rhcD"
      },
      "source": [
        "#Client_acc_40=np.zeros(len(noise))\n",
        "#Client_acc_20=np.zeros(len(noise))\n",
        "Client_acc_10=np.zeros(len(noise))   #compute accuracy for 10 number of model owners"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owwMVJfd5AWR"
      },
      "source": [
        "#add noise \n",
        "def add_noise_sum(noise,sum,experiment,ypred):\n",
        "  sum_s=sum\n",
        "  predt=np.zeros(experiment)\n",
        "  for i1 in range(experiment):\n",
        "    sum_s=np.zeros(sum.shape)\n",
        "    sum_f=sum+np.random.laplace(loc=0.0, scale=1/noise)\n",
        "    sum2=label(sum_f)\n",
        "    predt[i1]=accuracy_score(ypred,sum2)\n",
        "    #print(i)\n",
        "  pred=np.average(predt)\n",
        "  #print(predt)\n",
        "  #print(pred)\n",
        "  return pred\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO9L4uJbrtHY",
        "outputId": "2c046529-e455-42ec-c7a1-8548da92f3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noise=[.01,.02,.03, .05,.1,.3,.5,.7,.9,1]  #noise\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "#Noise after Aggregation Method\n",
        "for i in range(0,len(noise)):\n",
        "                          sum_s=np.zeros(sum.shape)\n",
        "                 #sum2=np.zeros(sum1.shape)\n",
        "                 #predF=0\n",
        "                 #y_label=0\n",
        "                          sum_n=sum\n",
        "                          #sum_s=sum_n+np.random.laplace(loc=0.0, scale=1/noise[i])\n",
        "                          predF=add_noise_sum(noise[i],sum_n,50,y_pred)\n",
        "                          #print(sum_s)\n",
        "\n",
        "                          #sum2=label(sum_s)\n",
        "                          #print(sum2)\n",
        "                          #y_label=label(y_test)\n",
        "                          #predF=accuracy_score(y_pred,sum2)\n",
        "#predF=average_precision_score(y_test,sum2)\n",
        "#print(predF)\n",
        "                          Client_acc_10[i]=predF*100\n",
        "print(Client_acc_10)\n",
        "#print(Client_acc1)\n",
        "print(noise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49.144 50.68  53.672 50.6   70.084 80.56  80.6   80.6   80.6   80.6  ]\n",
            "[0.01, 0.02, 0.03, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_52XdvNrruP-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "# plotting the points \n",
        "test1 = plt.figure()\n",
        "#plt.plot(noise, Client_acc_40, linestyle='--',marker='.',color='blue',label='Number of Model Owners=40',linewidth=1.2)  \n",
        "#plt.plot(noise, Client_acc_20,linestyle='--', marker='.',color='red',label='Number of Model Owners=20',linewidth=1.2)  \n",
        "plt.plot(noise, Client_acc_10, marker='.',color='black',label='Number of Model Owners=10',linewidth=1.2) \n",
        "# naming the x axis \n",
        "x=plt.xlabel('Privacy Budget, epsilon', fontsize='15') \n",
        "x.set_color(\"black\")\n",
        "# naming the y axis \n",
        "y=plt.ylabel('Inference Accuracy ',fontsize='15') \n",
        "y.set_color(\"black\")\n",
        "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
        "plt.rcParams[\"axes.linewidth\"] = 1\n",
        "plt.ylim((0,90))\n",
        "plt.xlim((0,1)) \n",
        "plt.xticks(np.arange(0, 1, .1)) \n",
        "plt.yticks(np.arange(0, 90, 10))\n",
        "plt.grid(b=None)\n",
        "#acc_final\n",
        "#plt.legend()\n",
        "\n",
        "plt.legend()\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "test1.show()\n",
        "test1.set_facecolor('white')\n",
        "test1.savefig('test1.pdf')\n",
        "#files.download('test1.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWpCuBkXmur"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "# plotting the points \n",
        "test1 = plt.figure()\n",
        "plt.plot(noise, Client_acc_40,linestyle='--', marker='.',color='black',label='Model Owners Vote Count',linewidth=2) \n",
        "plt.plot(noise, Client_acc_40_C,linestyle='--', marker='.',color='red',label='Sum of Confidence Value',linewidth=1.2)  \n",
        "#plt.plot(noise, Client_acc_10,linestyle='--', marker='*',color='blue',label='Number of Model Owners=10',linewidth=1.2) \n",
        "# naming the x axis \n",
        "x=plt.xlabel('Privacy Budget, epsilon', fontsize='15') \n",
        "x.set_color(\"black\")\n",
        "# naming the y axis \n",
        "y=plt.ylabel('Inference Accuracy ',fontsize='15') \n",
        "y.set_color(\"black\")\n",
        "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
        "plt.rcParams[\"axes.linewidth\"] = 1\n",
        "plt.ylim((0,90))\n",
        "plt.xlim((0,1)) \n",
        "plt.xticks(np.arange(0, 1, .1)) \n",
        "plt.yticks(np.arange(0, 90, 10))\n",
        "plt.grid(b=None)\n",
        "#acc_final\n",
        "#plt.legend()\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "plt.legend(loc=4)\n",
        "test1.show()\n",
        "test1.set_facecolor('white')\n",
        "test1.savefig('test1.pdf')\n",
        "#files.download('test1.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}